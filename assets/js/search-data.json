{
  
    
        "post0": {
            "title": "Downloading Coursera Material",
            "content": "Downloading Coursera Learning Material . Coursera Power User . I’ve been taking a ton of Coursera courses focuses on GCP during the lockdown. I really appreciate all the material that Coursera provides including pdfs, transcripts and of course all their videos. However, I was getting anoyed that I had to download each transcript one at a time and thought there must be a better way!? . coursera-dl - There is a better way! . coursera-dl . Coursera-dl is a quick cli to help semi-automate downloading all the course material at once! . Steps . pip install coursera-dl . | In your browser navigate to where your cookies are stored. . | For Chrome: . To navigate to this you can paste this in your brower: chrome://settings/siteData . Settings &gt; Privacy and Security &gt; site settings &gt; Cookies and site data &gt; See all cookies and site data &gt; Coursera.org . You will see: CAUTH listed, you will need the content later . Quick bash script | coursera-dl has many arguments. --help and look at what you might want. . I only wanted the transcripts/ txt and pdfs so I used the --ignore-formats mp4 argument to ignore the videos. . you can make a bash script by copy/paste this into a file like: coursera_material_download.sh . You will need to populate the various arguments. . # Quick script to grab course materials ​ ​ USER=&lt;COURSERA_USERNAME&gt; PASS=&lt;COURSERA_YOUR_PASSWORD&gt; ​ CAUTH=&lt;your cookies for coursera&gt; COURSES=&lt;course-name-from-URL&gt; ​ # ignore the videos coursera-dl -u $USER -p $PASS --ignore-formats mp4 -sl en -ca $CAUTH $COURSES . To run it: . $ bash coursera_material_download.sh .",
            "url": "https://cattleman.github.io/personal-blog/2020/05/08/downloading-coursera-material.html",
            "relUrl": "/2020/05/08/downloading-coursera-material.html",
            "date": " • May 8, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://cattleman.github.io/personal-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Descartes Labs Geospatial Platform Webinar",
            "content": "Descartes Labs Geospatial Platform Webinar . Website: https://www.descarteslabs.com/ . This past week I attended a half-hour Descartes Labs (DL) webinar to get an overview of the platform. I’ve been following DL for a few years now after learning about them from Planet, a satellite data company. DL has built a python api that makes the Planet satellite data very accessible as well as aggregating other satellite data sources like Landsat. . In addition to access to data, DL offers managed compute resources like a hosted jupyter labs instance for data scientists to build workflows. It wasn’t clear to me if customers can also schedule workflows and leverage DL’s managed resource too, but I would expect that’s the case. . It sounds like there are a few subscription tiers that offer more access to data sets and compute. . Overall I was really impressed by the api and pre-processing that DL does. The platform standardizes various projections from different satellites to allow users to work with data in a common basis. I think that is a big selling point for my use-case because it provides a much richer data-set AND is data prep I don’t have to do myself. . I am looking forward to diving into the data and further explore the API. . Questions: . Does the API / service support custom data-set creation? | If I want to use a data labeling service like figure-eight what is the best way to export images? | For custom data-sets how does IP / ownership work? | Next step: . Reach out to sales and get more specifics on the various subscription tiers. | .",
            "url": "https://cattleman.github.io/personal-blog/markdown/2020/02/20/Descartes-Lab-Geospatial-Platform.html",
            "relUrl": "/markdown/2020/02/20/Descartes-Lab-Geospatial-Platform.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "AWS Innovate - ML Online Conference",
            "content": "AWS Innovate: ML Online Conference . Last week I attended the AWS Innovate: ML online Conference. . Website: https://aws.amazon.com/events/aws-innovate/machine-learning/ . While I work in AWS ecosystem, I don’t have much exposure to the ML products/services and tools that AWS provides. This conference was a good way to get broad exposure to the various options and solutions AWS provides. I will admit that as I was watching various sessions I was working and chatting with collogues that were also watching various sessions. . Sessions I attended . Automate machine Learning: From Debugging DL to detecting model drift in Prod. | Simplify and accelerate time-series forecasting and real-time personalization | Amazon Kendra: Reinvent enterprise search and interact with data using AI | Large scale image and video analysis with Amazon Rekognition | My Take-aways . This session was fairly basic and addressed DL debugging tools that AWS SageMaker has to diagnose various issues with your model. The case-study was focused on vanishing gradient problem. For those unfamiliar, the vanishing gradient problem is when the gradients get very small. When the gradient is used to update the weight value there is almost no update so no learning can occur. (think of multiplying two small numbers, 0.1 * 0.1=0.01) The tooling that AWS provides for debugging DL models is really cool - I would definitely use it if I worked in SageMaker. Another part of this session was addressing drift. However, the example they used was to monitor the covariate shift /distribution of live data and verify that it has a similar distribution to the training data. I think of that more as a monitoring/validation check than drift. | I caught the last third of the time-series session. This was very validating because AWS’ product approaches time-series forecasting the same way I have been recently. They introduced a pyramid with classic methods at the base - ARIMA, GARCH, VEC STS. Then the middle tier was Facebook Prophet https://facebook.github.io/prophet/ which I first started using when it was released in 2017. (I recommend reading the paper: Forecasting at Scale: https://peerj.com/preprints/3190/). The top of the pyramid is an RNN - I am guessing AWS means a family of sequence models. My only exposure to RNNs has been in various tutorials - a major downside is the lack of interpretability which most business-cases desire. One question that came up was How much data do I need for RNNs (LSTM, GRU etc.)? | Amazon Kendra is a really exciting product. It’s ostensibly very simple - the combo of search and NLP. My head exploded with applications for Kendra at work and for various personal projects. . At work: Could we use Kendra to help make all the disparate docs and wiki’s more accessible and queryable? . Personal projects: Could I use Kendra to make all my online interactions queryable? . | Amazon Rekognition is AWS’ semi-automated computer vision / classification framework. They have a set of pre-trained models that you can leverage to label your own images and the capacity to build your own datasets and use transfer learning / tuning for custom projects. | AWS splits image analysis into three categories: Exemplar, Classification and Localization. Exemplar problems use a dataset of specific items you want to identify in other images. Your NN is trained on those images and inference is identifying if the item is present and if so what is the bounding box. A use-case they provide was brand recognition. . Classification - Think of classic MNIST use-cases. . Localization - Where your data includes bounding boxes. . Another part of the Rekognition stack was how to leverage a positive-feedback loop so that humans-in-the-loop can improve the dataset that is used to train subsequent versions of the model. I thought this was a valuable point because it helps people consider the data-flywheel from the get-go. The first version doesn’t need to have awesome F1 score if you have a process to improve the model as it serves inferences! . Overall, I thought the online conference was a good use of time - It’s helpful to see how AWS characterizes these various problem spaces and to see how each of the solutions fits in the ecosystem. .",
            "url": "https://cattleman.github.io/personal-blog/markdown/2020/02/19/AWS-Innovate-ML.html",
            "relUrl": "/markdown/2020/02/19/AWS-Innovate-ML.html",
            "date": " • Feb 19, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Starting Probabilistic Programming Primer",
            "content": "Starting Probabilistic Programming - with Probabilistic Programming Primer Course! . Probablistic Programming Primer . My motivation . I am motivated to build my intuition about probability and how to apply probabilistic thinking to decision making. Like many, I am heavily influenced by Taleb’s Icerto and seek to better understand uncertainty in the World. . Enter pymc3 . I first encountered pymc3 through blogs on the Quantopian trading environment/ platform. The notion that I could build models that shine a dim light around the “truth” appeals to me. I dove into Thomas Wiecki’s blog, but for the most part, it went over my head at the time. . Since then I got my feet wet with Pymc3 through Eric Ma and Hugo Bowne’s awesome 2018 scipy conference video tutorial: Here. Over a weekend I went through (quickly) the video and associated exercises. . I decided to follow as many of the pycm3 core devs that I could find on twitter. I’ve learned a lot from being a fly-on-the-wall of their various threads. Through twitter, I found George Ho’s awesome blog Eigenfoo: Here. . Another pymc3 dev I follow is is Peadar Coyle. I appreciate his perspective on all things stats/tech - Go Audio! I’ve also been salivating over his Probablistic Programming Primer course since he introduced it. . Probabilistic Programming Primer . First off - Thank you, Peadar for giving me the opportunity to take this course for free. I really appreciate the opportunity. . I am excited to take this course to help me better understand how to structure the model development process and build my statistical intuition. . What I hope to learn . How do practitioners think through selecting the distribution of priors? | How do I measure the performance of a probabilistic model? | How do I diagnose issues in my model? | How can I better communicate the results of a probabilistic model to stakeholders? | What is a trace? | . My plan is to work through the course over the next month with sporadic updates on my progress and a-ha moments along the way. At the end of the course, I’ll return to the questions above and share what I’ve learned and where I got confused. .",
            "url": "https://cattleman.github.io/personal-blog/markdown/2020/02/13/starting-probabilistic-programming-primer.html",
            "relUrl": "/markdown/2020/02/13/starting-probabilistic-programming-primer.html",
            "date": " • Feb 13, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://cattleman.github.io/personal-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Incerto",
          "content": "Incerto . What is Incerto? . Incerto is a body of work by Nassim Nicholas Taleb focused on uncertainty. . One of my goals for 2020 is to re-read the books and jot down my thoughts. I’ve re-read many of these over the past few years, but my perspective has changed in the last couple of years. . Fooled by Randomness . some thoughts from my head right after finishing: . Skeptic Update your belief slowly with new info (bayesian) | . | Don’t marry an idea or belief - you can change your mind! | We get cases of conditional probability wrong - It’s complicated! | Humans anchor on specifics - $10 mil if you die in 10 years VS $10 mil if you die in a car crash in 10 years. We can imagine the car crash so we’re more inclined to think it can happen. Imagining out death, however it happens, is difficult | . Specifics from the book where I folded the page (paraphrased): . Ergodicity - It means, that under certain conditions, that very long sample-path would end up resembling each other. Think Janitor’s lottery wealth (fools-luck) vs dentist’s. P.57 | Owing to abrupt rare events, we do not live in a world where things “converge” continuously towards betterment. Nor do things in life move continuously at all. NATURE DOES INFACT MAKE JUMPS. P.95 | Survivorship bias is dependent on the size of the initial population. Recall Taleb’s experiment with 10,000 managers. A track record has less relevance than we think. (p. 156) | (1) We do not think when making choices but use heuristics (2) We make serious probabilistic mistakes in today’s world - whatever the true reason. Also - 2200 years was not long ago. We are all Romans/greeks/Mongols. p.198 | Option blindness - What has more value? (a) a contract that pays $1m if the market goes down 10% on any given day in the next year; (b) a contract that pays you $ m if the stock market goes down 10% on any given day next year due to a terrorist act? I expect most ppl choose (b) (Anchor on specifics) p.210 | Wax in my ears | Say you own a painting you bought for 20k, the art market now values it at 40k. would you still acquire the painting at 40k? If not, you’re married to the position. There is no rational reason to keep the painting if you would not buy it at its current rate - only an emotional investment. Beliefs are said to be path-dependent if the sequence of ideas is such that the first one dominates. p.240 | The Black Swan . TODO The Bed of Procrustes . | TODO Antifragile . | TODO | .",
          "url": "https://cattleman.github.io/personal-blog/incerto/",
          "relUrl": "/incerto/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "About Me",
          "content": "Hello! I am a full-stack data scientist interested in the intersection of data, robotics, and agrictulture. I have a background in livestock/poultry and have worked in industry on a varity of problems inclding dynamic pricing, forecasting and image processing. I am motivated by complex problems and unique datasets. . My LinkedIn Profile . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://cattleman.github.io/personal-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}